{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import pyroomacoustics as pra\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import scipy.signal as sp\n",
    "import scipy as scipy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 順列計算に使用\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_wave_file = \"../data/raw/samaple/2speaker_yk.wav\"\n",
    "\n",
    "with wave.open(sample_wave_file) as wav:\n",
    "    # ファイルの情報を出力する\n",
    "    print(\"サンプリング周波数[Hz]:\", wav.getframerate())\n",
    "    print(\"サンプルサイズ[Byte]:\", wav.getsampwidth())\n",
    "    print(\"サンプル数:\", wav.getnframes())\n",
    "    print(\"チャンネル数:\", wav.getnchannels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 音量の変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceAudio = AudioSegment.from_wav(sample_wave_file)\n",
    "volume_delta = 50\n",
    "# 音量を上げる\n",
    "processedAudio = sourceAudio + volume_delta\n",
    "\n",
    "basename = os.path.basename(sample_wave_file)\n",
    "basename = os.path.splitext(basename)[0]\n",
    "new_filename = f\"{basename}_{volume_delta}.wav\"\n",
    "\n",
    "new_directory_path = os.path.join(os.path.dirname(sample_wave_file).replace(\"raw\", \"processed\"))\n",
    "os.makedirs(new_directory_path, exist_ok=True)\n",
    "\n",
    "dst_wave_file = os.path.join(new_directory_path, new_filename)\n",
    "processedAudio.export(dst_wave_file, format=\"wav\")\n",
    "\n",
    "with wave.open(dst_wave_file) as wav:\n",
    "    # ファイルの情報を出力する\n",
    "    print(\"サンプリング周波数[Hz]:\", wav.getframerate())\n",
    "    print(\"サンプルサイズ[Byte]:\", wav.getsampwidth())\n",
    "    print(\"サンプル数:\", wav.getnframes())\n",
    "    print(\"チャンネル数:\", wav.getnchannels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音量を上げた後もチャンネル数はそのまま保存できている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スマホでの録音データ分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m4aファイルを読み込み、wavに変換する\n",
    "def convert_m4a_to_wav(m4a_file_path):\n",
    "    audio = AudioSegment.from_file(m4a_file_path, \"m4a\")\n",
    "    wav_file_path = os.path.splitext(m4a_file_path)[0] + \".wav\"\n",
    "    audio.export(wav_file_path, format=\"wav\")\n",
    "    return wav_file_path\n",
    "\n",
    "sample_m4a_file = \"../data/raw/propeller/self_record/2023-07-07.m4a\"\n",
    "\n",
    "# m4aをwavに変換\n",
    "sample_wave_file = convert_m4a_to_wav(sample_m4a_file)\n",
    "\n",
    "# 変換したwavファイルの情報を出力する\n",
    "with wave.open(sample_wave_file) as wav:\n",
    "    print(\"サンプリング周波数[Hz]:\", wav.getframerate())\n",
    "    print(\"サンプルサイズ[Byte]:\", wav.getsampwidth())\n",
    "    print(\"サンプル数:\", wav.getnframes())\n",
    "    print(\"チャンネル数:\", wav.getnchannels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* スマホでの録音は 1 チャンネルだった\n",
    "* サンプリング周波数が TAMAGO の 2 倍だった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_pad_audio_files(wave_files):\n",
    "    audio_data = []\n",
    "    n_samples = 0\n",
    "    n_sources = len(wave_files)\n",
    "\n",
    "    for wave_file in wave_files:\n",
    "        with wave.open(wave_file) as wav:\n",
    "            data = wav.readframes(wav.getnframes())\n",
    "            data = np.frombuffer(data, dtype=np.int16)\n",
    "            n_samples = max(wav.getnframes(), n_samples)\n",
    "            data = data / np.iinfo(np.int16).max\n",
    "            audio_data.append(data)\n",
    "\n",
    "    for s in range(n_sources):\n",
    "        if len(audio_data[s]) < n_samples:\n",
    "            pad_width = n_samples - len(audio_data[s])\n",
    "            audio_data[s] = np.pad(audio_data[s], (0, pad_width), \"constant\")\n",
    "        audio_data[s] /= np.std(audio_data[s])\n",
    "    return audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "wave_files = [\"../data/raw/samaple/arctic_a0001.wav\", \"../data/raw/samaple/arctic_a0002.wav\"]\n",
    "audio_data = normalize_and_pad_audio_files(wave_files)\n",
    "\n",
    "# パラメータの設定\n",
    "n_sim_sources = 2\n",
    "sample_rate = 16000\n",
    "N = 1024\n",
    "Nk = int(N / 2 + 1)\n",
    "freqs = np.arange(0, Nk, 1) * sample_rate / N\n",
    "SNR = 90.0\n",
    "azimuth_th = 30.0\n",
    "room_dim = np.array([10.0, 10.0, 10.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "マイクロホンアレイの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_array_loc = room_dim / 2 + np.random.randn(3) * 0.1\n",
    "mic_directions = np.array([[np.pi / 2.0, theta / 180.0 * np.pi] for theta in np.arange(180, 361, 180)])\n",
    "\n",
    "distance = 0.01\n",
    "mic_alignments = np.zeros((3, mic_directions.shape[0]), dtype=mic_directions.dtype)\n",
    "mic_alignments[0, :] = np.cos(mic_directions[:, 1]) * np.sin(mic_directions[:, 0])\n",
    "print(mic_alignments[0, :], mic_alignments[0, :].shape)\n",
    "mic_alignments[1, :] = np.sin(mic_directions[:, 1]) * np.sin(mic_directions[:, 0])\n",
    "print(mic_alignments[1, :])\n",
    "# mic_alignments[2, :] = np.cos(mic_directions[:, 0])\n",
    "mic_alignments[2, :] = np.array([5, 5])\n",
    "# print(mic_alignments[2, :])\n",
    "mic_alignments *= distance\n",
    "print(mic_directions)\n",
    "print(mic_alignments)\n",
    "\n",
    "R = mic_alignments + mic_array_loc[:, None]\n",
    "room = pra.ShoeBox(room_dim, fs=sample_rate, max_order=0)\n",
    "room.add_microphone_array(pra.MicrophoneArray(R, fs=room.fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音源の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 場所\n",
    "doas = np.array([[np.pi / 2.0, np.pi], [np.pi / 2.0, 0]])\n",
    "# 音源とマイクロホンの距離\n",
    "distance = 1.0\n",
    "\n",
    "source_locations = np.zeros((3, doas.shape[0]), dtype=doas.dtype)\n",
    "source_locations[0, :] = np.cos(doas[:, 1]) * np.sin(doas[:, 0])\n",
    "source_locations[1, :] = np.sin(doas[:, 1]) * np.sin(doas[:, 0])\n",
    "# source_locations[2, :] = np.cos(doas[:, 0])\n",
    "source_locations *= distance\n",
    "source_locations += mic_array_loc[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "極座標系で指定する必要がないので修正が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mic_alignments.T)\n",
    "print(source_locations.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シミュレーションを回す\n",
    "for s in range(n_sim_sources):\n",
    "    room.add_source(source_locations[:, s], signal=audio_data[s])\n",
    "\n",
    "fig, ax = room.plot()\n",
    "print(\"Current elevation angle:\", ax.elev)  # 正面から上方向への角度\n",
    "print(\"Current azimuth angle:\", ax.azim)  # 真横から反時計回りの角度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_room_views(room):\n",
    "    # Create a new figure\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Create subplot for the top view\n",
    "    ax1 = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "    room.plot(fig=fig, ax=ax1)\n",
    "    ax1.view_init(90, -90)\n",
    "    ax1.set_title(\"Top View\")\n",
    "\n",
    "    # Create subplot for the front view\n",
    "    ax2 = fig.add_subplot(1, 3, 2, projection='3d')\n",
    "    room.plot(fig=fig, ax=ax2)\n",
    "    ax2.view_init(0, -90)\n",
    "    ax2.set_title(\"Front View\")\n",
    "\n",
    "    # Create subplot for the side view\n",
    "    ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n",
    "    room.plot(fig=fig, ax=ax3)\n",
    "    ax3.view_init(0, 0)\n",
    "    ax3.set_title(\"Side View\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_room_views(room)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room.simulate(snr=SNR)\n",
    "multi_conv_data = room.mic_array.signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(multi_conv_data))\n",
    "print(multi_conv_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(audio_data)=}\")\n",
    "print(f\"{audio_data[0].shape=}\")\n",
    "print(f\"{audio_data[1].shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.file_io import write_signal_to_wav, write_signal_to_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_signal_to_wav(multi_conv_data, \"../data/processed/multi_conv_data.wav\", sample_rate)\n",
    "write_signal_to_npz(multi_conv_data, \"../data/processed/multi_conv_data.npz\", sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
