{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyroomacoustics as pra\n",
    "from pyroomacoustics.doa import MUSIC\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.file_io import load_signal_from_wav, write_signal_to_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUSIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_music_spectrum(doa):\n",
    "    estimated_angles = doa.grid.azimuth\n",
    "    music_spectrum = doa.grid.values\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot the MUSIC spectrum in polar coordinates\n",
    "    plt.subplot(1, 2, 1, projection=\"polar\")\n",
    "    plt.polar(estimated_angles, music_spectrum)\n",
    "    plt.title(\"MUSIC Spectrum (Polar Coordinates)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot the MUSIC spectrum in Cartesian coordinates\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(np.rad2deg(estimated_angles), music_spectrum)  # Convert radians to degrees\n",
    "    plt.title(\"MUSIC Spectrum (Cartesian Coordinates)\")\n",
    "    plt.xlabel(\"Angle (degrees)\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D SSL with a Single Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_dim = [4, 4]\n",
    "corners = np.array([[0, 0], [0, room_dim[1]], room_dim, [room_dim[0], 0]]).T  # [x,y]\n",
    "\n",
    "# 2次元の部屋を作成\n",
    "room = pra.Room.from_corners(\n",
    "    corners,\n",
    "    fs=16000,\n",
    "    max_order=0,\n",
    ")\n",
    "\n",
    "# 音源の位置を定義\n",
    "sources_positions = np.array([[0.5, 0.5]])\n",
    "\n",
    "# 音源を部屋に追加\n",
    "signal = load_signal_from_wav(\"../data/processed/propeller/p2000_2/dst.wav\", room.fs)\n",
    "samples_per_source = len(signal) // len(sources_positions)\n",
    "for i, pos in enumerate(sources_positions):\n",
    "    room.add_source(pos, signal=signal[samples_per_source * i:samples_per_source * (i + 1)])\n",
    "\n",
    "# マイクロホンアレイの位置を計算\n",
    "mic_positions = pra.circular_2D_array(center=[2.,2.], M=8, phi0=0, radius=0.1)\n",
    "\n",
    "# マイクロホンアレイを部屋に追加\n",
    "mic_array = pra.MicrophoneArray(\n",
    "    mic_positions,  # マイクロホンの位置を更新\n",
    "    room.fs,  # サンプリング周波数\n",
    ")\n",
    "room.add_microphone_array(mic_array)\n",
    "\n",
    "room.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room.simulate(snr=10)\n",
    "simulated_signals = room.mic_array.signals\n",
    "write_signal_to_wav(simulated_signals, \"hoge.wav\", room.fs)\n",
    "simulated_signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFTの長さとホップサイズを定義\n",
    "nfft = 512\n",
    "hop_size = nfft // 2\n",
    "\n",
    "# シミュレートされた信号をフレームに分割し、FFTを計算\n",
    "num_frames = (simulated_signals.shape[1] - nfft) // hop_size + 1\n",
    "X = np.empty((simulated_signals.shape[0], nfft // 2 + 1, num_frames), dtype=complex)\n",
    "\n",
    "for t in range(num_frames):\n",
    "    frame = simulated_signals[:, t*hop_size:t*hop_size+nfft]\n",
    "    X[:, :, t] = np.fft.rfft(frame, n=nfft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUSICインスタンスを作成\n",
    "doa = MUSIC(\n",
    "    L=mic_positions,\n",
    "    fs=room.fs,\n",
    "    nfft=nfft,\n",
    "    c=343.0,\n",
    "    num_src=len(sources_positions),\n",
    "    mode=\"far\",\n",
    "    azimuth=np.linspace(-np.pi, np.pi, 360)\n",
    ")\n",
    "\n",
    "# 3次元配列を使用してMUSIC法を適用\n",
    "doa.locate_sources(X, freq_range=[300, 3500])\n",
    "\n",
    "# 推定された方向を取得\n",
    "estimated_angles = doa.azimuth_recon\n",
    "\n",
    "print(\"推定された音源の方向（ラジアン）:\", estimated_angles)\n",
    "print(\"推定された音源の方向（度）:\", np.rad2deg(estimated_angles))\n",
    "plot_music_spectrum(doa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "円状だと、線状のように線対称で角度が不明な場合とは異なり、角度が明らかになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D SSL with Multiple Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_dim = [4, 4]\n",
    "corners = np.array([[0, 0], [0, room_dim[1]], room_dim, [room_dim[0], 0]]).T  # [x,y]\n",
    "\n",
    "# 2次元の部屋を作成\n",
    "room = pra.Room.from_corners(\n",
    "    corners,\n",
    "    fs=16000,\n",
    "    max_order=0,\n",
    ")\n",
    "\n",
    "# 音源の位置を定義\n",
    "sources_positions = np.array([[0.5, 0.5], [2, 3.2], [3.5, 2]])\n",
    "\n",
    "# 音源を部屋に追加\n",
    "signal = load_signal_from_wav(\"../data/processed/propeller/p2000_2/dst.wav\", room.fs)\n",
    "samples_per_source = len(signal) // len(sources_positions)\n",
    "for i, pos in enumerate(sources_positions):\n",
    "    room.add_source(pos, signal=signal[samples_per_source * i:samples_per_source * (i + 1)])\n",
    "\n",
    "# マイクロホンアレイの位置を計算\n",
    "mic_positions = pra.circular_2D_array(center=[2.,2.], M=8, phi0=0, radius=0.1)\n",
    "\n",
    "# マイクロホンアレイを部屋に追加\n",
    "mic_array = pra.MicrophoneArray(mic_positions, room.fs)\n",
    "room.add_microphone_array(mic_array)\n",
    "\n",
    "room.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room.simulate(snr=90)\n",
    "simulated_signals = room.mic_array.signals\n",
    "write_signal_to_wav(simulated_signals, \"hoge.wav\", room.fs)\n",
    "simulated_signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFTの長さとホップサイズを定義\n",
    "nfft = 512\n",
    "hop_size = nfft // 2\n",
    "\n",
    "# シミュレートされた信号をフレームに分割し、FFTを計算\n",
    "num_frames = (simulated_signals.shape[1] - nfft) // hop_size + 1\n",
    "X = np.empty((simulated_signals.shape[0], nfft // 2 + 1, num_frames), dtype=complex)\n",
    "\n",
    "for t in range(num_frames):\n",
    "    frame = simulated_signals[:, t*hop_size:t*hop_size+nfft]\n",
    "    X[:, :, t] = np.fft.rfft(frame, n=nfft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUSICインスタンスを作成\n",
    "doa = MUSIC(\n",
    "    L=mic_positions,\n",
    "    fs=room.fs,\n",
    "    nfft=nfft,\n",
    "    c=343.0,\n",
    "    num_src=len(sources_positions),\n",
    "    mode=\"near\",\n",
    "    azimuth=np.linspace(-np.pi, np.pi, 360)\n",
    ")\n",
    "\n",
    "# 3次元配列を使用してMUSIC法を適用\n",
    "doa.locate_sources(X, freq_range=[300, 3500])\n",
    "\n",
    "# 推定された方向を取得\n",
    "estimated_angles = doa.azimuth_recon\n",
    "\n",
    "print(\"推定された音源の方向（ラジアン）:\", estimated_angles)\n",
    "print(\"推定された音源の方向（度）:\", np.rad2deg(estimated_angles))\n",
    "plot_music_spectrum(doa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "円状だと複数音源の定位も余裕だった"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNR を小さくしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room.simulate(snr=-5)\n",
    "simulated_signals = room.mic_array.signals\n",
    "write_signal_to_wav(simulated_signals, \"hoge.wav\", room.fs)\n",
    "\n",
    "# FFTの長さとホップサイズを定義\n",
    "nfft = 512\n",
    "hop_size = nfft // 2\n",
    "\n",
    "# シミュレートされた信号をフレームに分割し、FFTを計算\n",
    "num_frames = (simulated_signals.shape[1] - nfft) // hop_size + 1\n",
    "X = np.empty((simulated_signals.shape[0], nfft // 2 + 1, num_frames), dtype=complex)\n",
    "\n",
    "for t in range(num_frames):\n",
    "    frame = simulated_signals[:, t*hop_size:t*hop_size+nfft]\n",
    "    X[:, :, t] = np.fft.rfft(frame, n=nfft)\n",
    "\n",
    "# MUSICインスタンスを作成\n",
    "doa = MUSIC(\n",
    "    L=mic_positions,\n",
    "    fs=room.fs,\n",
    "    nfft=nfft,\n",
    "    c=343.0,\n",
    "    num_src=len(sources_positions),\n",
    "    mode=\"near\",\n",
    "    azimuth=np.linspace(-np.pi, np.pi, 360)\n",
    ")\n",
    "\n",
    "# 3次元配列を使用してMUSIC法を適用\n",
    "doa.locate_sources(X, freq_range=[300, 3500])\n",
    "\n",
    "# 推定された方向を取得\n",
    "estimated_angles = doa.azimuth_recon\n",
    "\n",
    "print(\"推定された音源の方向（ラジアン）:\", estimated_angles)\n",
    "print(\"推定された音源の方向（度）:\", np.rad2deg(estimated_angles))\n",
    "plot_music_spectrum(doa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNR が小さくなっても定位ができている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 半径を大きくしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_dim = [4, 4]\n",
    "corners = np.array([[0, 0], [0, room_dim[1]], room_dim, [room_dim[0], 0]]).T  # [x,y]\n",
    "\n",
    "# 2次元の部屋を作成\n",
    "room = pra.Room.from_corners(\n",
    "    corners,\n",
    "    fs=16000,\n",
    "    max_order=0,\n",
    ")\n",
    "\n",
    "# 音源の位置を定義\n",
    "sources_positions = np.array([[0.5, 0.5], [2, 3.2], [3.5, 2]])\n",
    "\n",
    "# 音源を部屋に追加\n",
    "signal = load_signal_from_wav(\"../data/processed/propeller/p2000_2/dst.wav\", room.fs)\n",
    "samples_per_source = len(signal) // len(sources_positions)\n",
    "for i, pos in enumerate(sources_positions):\n",
    "    room.add_source(pos, signal=signal[samples_per_source * i:samples_per_source * (i + 1)])\n",
    "\n",
    "# マイクロホンアレイの位置を計算\n",
    "mic_positions = pra.circular_2D_array(center=[2.,2.], M=8, phi0=0, radius=0.3)\n",
    "\n",
    "# マイクロホンアレイを部屋に追加\n",
    "mic_array = pra.MicrophoneArray(mic_positions, room.fs)\n",
    "room.add_microphone_array(mic_array)\n",
    "\n",
    "room.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room.simulate(snr=-5)\n",
    "simulated_signals = room.mic_array.signals\n",
    "write_signal_to_wav(simulated_signals, \"hoge.wav\", room.fs)\n",
    "\n",
    "# FFTの長さとホップサイズを定義\n",
    "nfft = 512\n",
    "hop_size = nfft // 2\n",
    "\n",
    "# シミュレートされた信号をフレームに分割し、FFTを計算\n",
    "num_frames = (simulated_signals.shape[1] - nfft) // hop_size + 1\n",
    "X = np.empty((simulated_signals.shape[0], nfft // 2 + 1, num_frames), dtype=complex)\n",
    "\n",
    "for t in range(num_frames):\n",
    "    frame = simulated_signals[:, t*hop_size:t*hop_size+nfft]\n",
    "    X[:, :, t] = np.fft.rfft(frame, n=nfft)\n",
    "\n",
    "# MUSICインスタンスを作成\n",
    "doa = MUSIC(\n",
    "    L=mic_positions,\n",
    "    fs=room.fs,\n",
    "    nfft=nfft,\n",
    "    c=343.0,\n",
    "    num_src=len(sources_positions),\n",
    "    mode=\"near\",\n",
    "    azimuth=np.linspace(-np.pi, np.pi, 360)\n",
    ")\n",
    "\n",
    "# 3次元配列を使用してMUSIC法を適用\n",
    "doa.locate_sources(X, freq_range=[300, 3500])\n",
    "\n",
    "# 推定された方向を取得\n",
    "estimated_angles = doa.azimuth_recon\n",
    "\n",
    "print(\"推定された音源の方向（ラジアン）:\", estimated_angles)\n",
    "print(\"推定された音源の方向（度）:\", np.rad2deg(estimated_angles))\n",
    "plot_music_spectrum(doa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_dim = [4, 4]\n",
    "corners = np.array([[0, 0], [0, room_dim[1]], room_dim, [room_dim[0], 0]]).T  # [x,y]\n",
    "\n",
    "# 2次元の部屋を作成\n",
    "room = pra.Room.from_corners(\n",
    "    corners,\n",
    "    fs=16000,\n",
    "    max_order=0,\n",
    ")\n",
    "\n",
    "# 音源の位置を定義\n",
    "sources_positions = np.array([[0.5, 0.5], [2, 3.2], [3.5, 2]])\n",
    "\n",
    "# 音源を部屋に追加\n",
    "signal = load_signal_from_wav(\"../data/processed/propeller/p2000_2/dst.wav\", room.fs)\n",
    "samples_per_source = len(signal) // len(sources_positions)\n",
    "for i, pos in enumerate(sources_positions):\n",
    "    room.add_source(pos, signal=signal[samples_per_source * i:samples_per_source * (i + 1)])\n",
    "\n",
    "# マイクロホンアレイの位置を計算\n",
    "mic_positions = pra.circular_2D_array(center=[2.,2.], M=8, phi0=0, radius=0.5)\n",
    "\n",
    "# マイクロホンアレイを部屋に追加\n",
    "mic_array = pra.MicrophoneArray(mic_positions, room.fs)\n",
    "room.add_microphone_array(mic_array)\n",
    "\n",
    "room.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room.simulate(snr=-5)\n",
    "simulated_signals = room.mic_array.signals\n",
    "write_signal_to_wav(simulated_signals, \"hoge.wav\", room.fs)\n",
    "\n",
    "# FFTの長さとホップサイズを定義\n",
    "nfft = 512\n",
    "hop_size = nfft // 2\n",
    "\n",
    "# シミュレートされた信号をフレームに分割し、FFTを計算\n",
    "num_frames = (simulated_signals.shape[1] - nfft) // hop_size + 1\n",
    "X = np.empty((simulated_signals.shape[0], nfft // 2 + 1, num_frames), dtype=complex)\n",
    "\n",
    "for t in range(num_frames):\n",
    "    frame = simulated_signals[:, t*hop_size:t*hop_size+nfft]\n",
    "    X[:, :, t] = np.fft.rfft(frame, n=nfft)\n",
    "\n",
    "# MUSICインスタンスを作成\n",
    "doa = MUSIC(\n",
    "    L=mic_positions,\n",
    "    fs=room.fs,\n",
    "    nfft=nfft,\n",
    "    c=343.0,\n",
    "    num_src=len(sources_positions),\n",
    "    mode=\"near\",\n",
    "    azimuth=np.linspace(-np.pi, np.pi, 360)\n",
    ")\n",
    "\n",
    "# 3次元配列を使用してMUSIC法を適用\n",
    "doa.locate_sources(X, freq_range=[300, 3500])\n",
    "\n",
    "# 推定された方向を取得\n",
    "estimated_angles = doa.azimuth_recon\n",
    "\n",
    "print(\"推定された音源の方向（ラジアン）:\", estimated_angles)\n",
    "print(\"推定された音源の方向（度）:\", np.rad2deg(estimated_angles))\n",
    "plot_music_spectrum(doa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "半径は小さい方がよさそう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 半径を小さくしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_dim = [4, 4]\n",
    "corners = np.array([[0, 0], [0, room_dim[1]], room_dim, [room_dim[0], 0]]).T  # [x,y]\n",
    "\n",
    "# 2次元の部屋を作成\n",
    "room = pra.Room.from_corners(\n",
    "    corners,\n",
    "    fs=16000,\n",
    "    max_order=0,\n",
    ")\n",
    "\n",
    "# 音源の位置を定義\n",
    "sources_positions = np.array([[0.5, 0.5], [2, 3.2], [3.5, 2]])\n",
    "\n",
    "# 音源を部屋に追加\n",
    "signal = load_signal_from_wav(\"../data/processed/propeller/p2000_2/dst.wav\", room.fs)\n",
    "samples_per_source = len(signal) // len(sources_positions)\n",
    "for i, pos in enumerate(sources_positions):\n",
    "    room.add_source(pos, signal=signal[samples_per_source * i:samples_per_source * (i + 1)])\n",
    "\n",
    "# マイクロホンアレイの位置を計算\n",
    "mic_positions = pra.circular_2D_array(center=[2.,2.], M=8, phi0=0, radius=0.05)\n",
    "\n",
    "# マイクロホンアレイを部屋に追加\n",
    "mic_array = pra.MicrophoneArray(mic_positions, room.fs)\n",
    "room.add_microphone_array(mic_array)\n",
    "\n",
    "room.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room.simulate(snr=-5)\n",
    "simulated_signals = room.mic_array.signals\n",
    "write_signal_to_wav(simulated_signals, \"hoge.wav\", room.fs)\n",
    "\n",
    "# FFTの長さとホップサイズを定義\n",
    "nfft = 512\n",
    "hop_size = nfft // 2\n",
    "\n",
    "# シミュレートされた信号をフレームに分割し、FFTを計算\n",
    "num_frames = (simulated_signals.shape[1] - nfft) // hop_size + 1\n",
    "X = np.empty((simulated_signals.shape[0], nfft // 2 + 1, num_frames), dtype=complex)\n",
    "\n",
    "for t in range(num_frames):\n",
    "    frame = simulated_signals[:, t*hop_size:t*hop_size+nfft]\n",
    "    X[:, :, t] = np.fft.rfft(frame, n=nfft)\n",
    "\n",
    "# MUSICインスタンスを作成\n",
    "doa = MUSIC(\n",
    "    L=mic_positions,\n",
    "    fs=room.fs,\n",
    "    nfft=nfft,\n",
    "    c=343.0,\n",
    "    num_src=len(sources_positions),\n",
    "    mode=\"near\",\n",
    "    azimuth=np.linspace(-np.pi, np.pi, 360)\n",
    ")\n",
    "\n",
    "# 3次元配列を使用してMUSIC法を適用\n",
    "doa.locate_sources(X, freq_range=[300, 3500])\n",
    "\n",
    "# 推定された方向を取得\n",
    "estimated_angles = doa.azimuth_recon\n",
    "\n",
    "print(\"推定された音源の方向（ラジアン）:\", estimated_angles)\n",
    "print(\"推定された音源の方向（度）:\", np.rad2deg(estimated_angles))\n",
    "plot_music_spectrum(doa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_dim = [4, 4]\n",
    "corners = np.array([[0, 0], [0, room_dim[1]], room_dim, [room_dim[0], 0]]).T  # [x,y]\n",
    "\n",
    "# 2次元の部屋を作成\n",
    "room = pra.Room.from_corners(\n",
    "    corners,\n",
    "    fs=16000,\n",
    "    max_order=0,\n",
    ")\n",
    "\n",
    "# 音源の位置を定義\n",
    "sources_positions = np.array([[0.5, 0.5], [2, 3.2], [3.5, 2]])\n",
    "\n",
    "# 音源を部屋に追加\n",
    "signal = load_signal_from_wav(\"../data/processed/propeller/p2000_2/dst.wav\", room.fs)\n",
    "samples_per_source = len(signal) // len(sources_positions)\n",
    "for i, pos in enumerate(sources_positions):\n",
    "    room.add_source(pos, signal=signal[samples_per_source * i:samples_per_source * (i + 1)])\n",
    "\n",
    "# マイクロホンアレイの位置を計算\n",
    "mic_positions = pra.circular_2D_array(center=[2.,2.], M=8, phi0=0, radius=0.01)\n",
    "\n",
    "# マイクロホンアレイを部屋に追加\n",
    "mic_array = pra.MicrophoneArray(mic_positions, room.fs)\n",
    "room.add_microphone_array(mic_array)\n",
    "\n",
    "room.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room.simulate(snr=-5)\n",
    "simulated_signals = room.mic_array.signals\n",
    "write_signal_to_wav(simulated_signals, \"hoge.wav\", room.fs)\n",
    "\n",
    "# FFTの長さとホップサイズを定義\n",
    "nfft = 512\n",
    "hop_size = nfft // 2\n",
    "\n",
    "# シミュレートされた信号をフレームに分割し、FFTを計算\n",
    "num_frames = (simulated_signals.shape[1] - nfft) // hop_size + 1\n",
    "X = np.empty((simulated_signals.shape[0], nfft // 2 + 1, num_frames), dtype=complex)\n",
    "\n",
    "for t in range(num_frames):\n",
    "    frame = simulated_signals[:, t*hop_size:t*hop_size+nfft]\n",
    "    X[:, :, t] = np.fft.rfft(frame, n=nfft)\n",
    "\n",
    "# MUSICインスタンスを作成\n",
    "doa = MUSIC(\n",
    "    L=mic_positions,\n",
    "    fs=room.fs,\n",
    "    nfft=nfft,\n",
    "    c=343.0,\n",
    "    num_src=len(sources_positions),\n",
    "    mode=\"near\",\n",
    "    azimuth=np.linspace(-np.pi, np.pi, 360)\n",
    ")\n",
    "\n",
    "# 3次元配列を使用してMUSIC法を適用\n",
    "doa.locate_sources(X, freq_range=[300, 3500])\n",
    "\n",
    "# 推定された方向を取得\n",
    "estimated_angles = doa.azimuth_recon\n",
    "\n",
    "print(\"推定された音源の方向（ラジアン）:\", estimated_angles)\n",
    "print(\"推定された音源の方向（度）:\", np.rad2deg(estimated_angles))\n",
    "plot_music_spectrum(doa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "半径は小さすぎてもダメで、0.1 くらいがよさそう"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
